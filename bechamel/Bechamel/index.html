<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Bechamel (bechamel.Bechamel)</title><link rel="stylesheet" href="../../odoc.css"/><meta charset="utf-8"/><meta name="generator" content="odoc 2.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> â€“ <a href="../index.html">bechamel</a> &#x00BB; Bechamel</nav><header class="odoc-preamble"><h1>Module <code><span>Bechamel</span></code></h1></header><nav class="odoc-toc"><ul><li><a href="#bechamel,-a-simple-and-agnostic-micro-benchmarking-framework.">Bechamel, a simple and agnostic micro-benchmarking framework.</a><ul><li><a href="#how-to-use-bechamel?">How to use Bechamel?</a><ul><li><a href="#make-a-test.">Make a test.</a></li><li><a href="#run-the-benchmark.">Run the benchmark.</a></li><li><a href="#analyze-results.">Analyze results.</a></li><li><a href="#show-results.">Show results.</a></li></ul></li></ul></li></ul></nav><div class="odoc-content"><h2 id="bechamel,-a-simple-and-agnostic-micro-benchmarking-framework."><a href="#bechamel,-a-simple-and-agnostic-micro-benchmarking-framework." class="anchor"></a>Bechamel, a simple and agnostic micro-benchmarking framework.</h2><p>Bechamel is a simple and <i>agnostic</i> micro-benchmarking framework to help the developer prove and compare metrics for a given <b>small</b> function. It's measuring the performance of something &quot;small&quot;, like a system call. Bechamel does not do, as we say, a macro-benchmark which can show a performance regression or I/O congestion for instance.</p><p>It just permits to assert that a simple call of a small function <code>fn1</code> can be faster than a call of another small function <code>fn2</code> (if you use a <i>time</i> metric). In this way, it asserts that <code>fn1</code> should be more efficient than <code>fn2</code> and it lets the developer <b>deduce</b> the best choice according to the runtime context.</p><p>Bechamel should <b>not</b> lead to premature optimization. It gives only clues/metrics about what you use, but you <b>must</b> recontextualize results according to your case to lead to <i>certain</i> optimizations.</p><h3 id="how-to-use-bechamel?"><a href="#how-to-use-bechamel?" class="anchor"></a>How to use Bechamel?</h3><p>Bechamel is split into 3 parts:</p><ul><li>A user interface to define <i>tests</i> (your small function)</li><li>A <i>runner</i> which will record required metrics</li><li>An <i>analyzer</i> which will analyze <i>raw</i> metrics and give you a stated result</li></ul><p>This is the core of Bechamel where the user is able to:</p><ul><li>define its own tests</li><li>use its own metrics</li><li>have a choice between 2 analyses (for instance, Ordinary Least Square analysis or RANdom SAmple Consensus analysis)</li></ul><h4 id="make-a-test."><a href="#make-a-test." class="anchor"></a>Make a test.</h4><p>The <a href="Test/index.html"><code>Test</code></a> gives an API which permits defining your tests. Let's take the example of the recursive factorial and the &quot;imperative&quot; factorial:</p><pre><code>let rec fact0 n =
  if n = 0 then 1
  else n * fact0 (n - 1)

let fact1 n =
  let m = ref 0 in
  let v = ref 1 in
  while !m &lt; n do
    m := !m + 1 ;
    v := !v * !m ;
  done ; !v</code></pre><p>From these small functions, we are able to make a test for each function and group them into one test:</p><pre><code>let test0 = Test.make ~name:&quot;recursive&quot;
  (Staged.stage @@ fun () -&gt; fact0 120)
let test1 = Test.make ~name:&quot;imperative&quot;
  (Staged.stage @@ fun () -&gt; fact1 120)
let test  = Test.make_grouped ~name:&quot;factorial&quot; ~fmt:&quot;%s %s&quot;
  [ test0; test1; ]</code></pre><p>The user is able to make multiple kinds of tests:</p><ul><li>A simple one as we did above</li><li>An indexed one which can take an <code>int</code> as an argument. For instance, we can execute our <code>fact</code> function with a set of <code>int</code>s.</li><li>A test which requires a &quot;resource&quot; which must be allocated before the <i>benchmark</i> and released after. For instance, we can allocate a <i>socket</i>, run <code>Unix</code>.write and record metrics and release (<code>Unix</code>.close) the resource then.</li><li>Finally, we can define an <i>indexed</i> test with a required resource</li></ul><h4 id="run-the-benchmark."><a href="#run-the-benchmark." class="anchor"></a>Run the benchmark.</h4><p>Then, you need to run the benchmark and record metrics. Bechamel is <i>agnostic</i> to the system: it permits recording a few metrics like the <a href="Toolkit/Instance/index.html#val-monotonic_clock"><code>Toolkit.Instance.monotonic_clock</code></a> or how many words were allocated into the minor heap <a href="Toolkit/Instance/index.html#val-minor_allocated"><code>Toolkit.Instance.minor_allocated</code></a>.</p><p>Depending on the execution context, the user is able to add some new metrics. For instance, on Linux, you can record the <code>Bechamel_perf</code>.Instance.cpu_clock - but it's not a part of the core distribution. More abstractly, Bechamel is able to record any metrics as far as the user is able to provide a <a href="S/module-type-MEASURE/index.html"><code>Bechamel.S.MEASURE</code></a>.</p><p>For instance, we will try to record the monotonic clock: it represents the absolute elapsed <i>wall-clock</i> time since an arbitrary, fixed point in the past (usually, the time since the program began running).</p><pre><code>let benchmark () =
  let instances = Instance.[ monotonic_clock ] in
  let cfg = Benchmark.cfg ~limit:2000 ~stabilize:true
    ~quota:(Time.second 0.5) () in
  Benchmark.all cfg instances tests</code></pre><p>The benchmark has many options and you should take a look at <a href="Benchmark/index.html#val-cfg"><code>Benchmark.cfg</code></a>. They permit to refine the context of the execution. For instance, you can <i>stabilize</i> the garbage-collector.</p><p>The function gives you <i>raw</i> results (see <a href="Measurement_raw/index.html"><code>Measurement_raw</code></a>). You can manipulate it as is or analyze it to extract useful information.</p><h4 id="analyze-results."><a href="#analyze-results." class="anchor"></a>Analyze results.</h4><p>Finally, you probably want to know the time spent by our factorial functions! This result requires to analyze our metrics. Indeed, if you run one time <code>fact0</code> and record the monotonic clock, you will probably get a <i>partial</i> result which fluctuated a lot per run:</p><pre><code>$ cat &gt;main.ml &lt;&lt;EOF
&gt; let rec fact0 x =
&gt;   if x = 0 then 1
&gt;   else x * fact0 (x - 1)
&gt; 
&gt; let () =
&gt;   let t0 = Unix.gettimeofday () in
&gt;   let _  = fact0 200 in
&gt;   let t1 = Unix.gettimeofday () in
&gt;   Format.printf &quot;%f\n%!&quot; (t1 -. t0)
&gt; EOF
$ ocamlfind opt -package unix -linkpkg main.ml
$ ./a.out
0.000001
$ ./a.out
0.000003</code></pre><p>This is why Bechamel exists. From metrics, it can estimate the time spent by our test. There are 2 methods to do that:</p><ul><li>calculate the Ordinary Least Square from metrics</li><li>calculate the RANdom Sample Consensus from metrics</li></ul><p>In our cases, we will use <a href="Analyze/index.html#val-ols"><code>Analyze.ols</code></a>:</p><pre><code>let analyze results =
  let ols = Analyze.ols ~bootstrap:0 ~r_square:true
    ~predictors:[| Measure.run |] in
  let results = Analyze.all ols Instance.monotonic_clock results in
  Analyze.merge ols [ Instance.monotonic_clock ] [ results ]</code></pre><p>The main question behind this function is: I would like to compare what with what? By default, the benchmark iterates a <i>certain</i> time on your function. For each iteration, it will execute <i>run</i> time(s) your function and this number increases for each iteration:</p><pre>  +-----+------+------------+
  | run | time |call of [fn]|
  +-----+------+------------+
  | 1   | 19   | 1          |
  | 2   | 25   | 2          |
  | 3   | 37   | 3          |
  | 4   | 47   | 4          |
  | 5   | 56   | 5          |
  +-----+------+------------+</pre><p>From these metrics, we can fit a curve: <code>a * x + b = y</code> where, from our code, <code>x = Measure.run</code> and <code>y = Instance.monotonic_clock</code>. OLS and RANSAC are algorithms which try to fit this curve. Then, <code>a</code> will become the time spent by our function for <code>x = 1</code> and this is what we want:</p><p>&gt; How much time do I spend if I call my function <b>one time</b>?</p><p>Some details differ between OLS and RANSAC but the documentation can help you to determine which one you should take.</p><h4 id="show-results."><a href="#show-results." class="anchor"></a>Show results.</h4><p>Bechamel has many ways to show results, but the core still is agnostic to the system and does not need anything (like <code>Unix</code>) to show results. However, the distribution comes with many possibilities:</p><ul><li>A <code>notty</code> which shows your results in a terminal</li><li>An HTML + JavaScript which produces an <code>index.html</code></li></ul><p>We will try to show the results <i>via</i> our terminal, but the HTML + JavaScript support has the ability to show you more information (such as the curve for instance):</p><pre><code>let () = Bechamel_notty.Unit.add
  Instance.monotonic_clock
  (Measure.unit Instance.monotonic_clock)

let img (window, results) =
  Bechamel_notty.Multiple.image_of_ols_results ~rect:window
    ~predictor:Measure.run results

open Notty_unix

let () =
  let window =
    match winsize Unix.stdout with
    | Some (w, h) -&gt; { Bechamel_notty.w; h }
    | None -&gt; { Bechamel_notty.w= 80; h= 1; } in
  let results = benchmark () in
  let results = analyze results in
  img (window, results) |&gt; eol |&gt; output_image</code></pre><p>You can compile (with <code>dune</code>) the program with:</p><pre><code>$ cat &gt;dune &lt;&lt;EOF
&gt; (executable
&gt;  (name example)
&gt;  (modules example)
&gt;  (libraries bechamel notty.unix bechamel-notty))
&gt; EOF
$ dune build ./example.exe
$ dune exec ./example.exe
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚name                    â”‚  monotonic-clock          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  factorial functional  â”‚            643.0477 ns/runâ”‚
â”‚  factorial imperative  â”‚            129.1994 ns/runâ”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</code></pre><div class="odoc-spec"><div class="spec module" id="module-S" class="anchored"><a href="#module-S" class="anchor"></a><code><span><span class="keyword">module</span> <a href="S/index.html">S</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Measure" class="anchored"><a href="#module-Measure" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Measure/index.html">Measure</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Benchmark" class="anchored"><a href="#module-Benchmark" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Benchmark/index.html">Benchmark</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Test" class="anchored"><a href="#module-Test" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Test/index.html">Test</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Staged" class="anchored"><a href="#module-Staged" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Staged/index.html">Staged</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div><div class="spec-doc"><p>Staged value.</p></div></div><div class="odoc-spec"><div class="spec module" id="module-Measurement_raw" class="anchored"><a href="#module-Measurement_raw" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Measurement_raw/index.html">Measurement_raw</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Linear_algebra" class="anchored"><a href="#module-Linear_algebra" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Linear_algebra/index.html">Linear_algebra</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Analyze" class="anchored"><a href="#module-Analyze" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Analyze/index.html">Analyze</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div><div class="spec-doc"><p>Analyze module.</p></div></div><div class="odoc-spec"><div class="spec module" id="module-Toolkit" class="anchored"><a href="#module-Toolkit" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Toolkit/index.html">Toolkit</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div><div class="odoc-spec"><div class="spec module" id="module-Time" class="anchored"><a href="#module-Time" class="anchor"></a><code><span><span class="keyword">module</span> <a href="Time/index.html">Time</a></span><span> : <span class="keyword">sig</span> ... <span class="keyword">end</span></span></code></div></div></div></body></html>